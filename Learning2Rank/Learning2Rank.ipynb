{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os.path import expanduser, join\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.txt 150000 138\n",
      "process:  0\n",
      "process:  10000\n",
      "process:  20000\n",
      "process:  30000\n",
      "process:  40000\n",
      "process:  50000\n",
      "process:  60000\n",
      "process:  70000\n",
      "process:  80000\n",
      "process:  90000\n",
      "process:  100000\n",
      "process:  110000\n",
      "process:  120000\n",
      "process:  130000\n",
      "process:  140000\n",
      "test.txt 50000 138\n",
      "process:  0\n",
      "process:  10000\n",
      "process:  20000\n",
      "process:  30000\n",
      "process:  40000\n",
      "vali.txt 50000 138\n",
      "process:  0\n",
      "process:  10000\n",
      "process:  20000\n",
      "process:  30000\n",
      "process:  40000\n",
      "Done\n",
      "CPU times: user 6min 36s, sys: 1.57 s, total: 6min 37s\n",
      "Wall time: 6min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the data into numpy version.\n",
    "# note that this will take some miniutes. Be patient :)\n",
    "def initialize():\n",
    "    path_prefix = '/Users/Jason/Desktop/book/Learn2Rank/MSLR-WEB10K/Fold1/'\n",
    "    # data_dict = {test:[x_train, y_train, qid_train]}\n",
    "    data_dict = {}\n",
    "    filenames = [\"train.txt\", \"test.txt\", \"vali.txt\"]\n",
    "    for filename in filenames:\n",
    "        if filename not in data_dict:\n",
    "            data_dict[filename] = []\n",
    "        data = pd.read_csv(path_prefix + filename, header=None, sep=' ')\n",
    "        # x_train, y_train, qid_train\n",
    "        rows = data.shape[0]\n",
    "        columns = data.shape[1] - 1  # note that remove last ' '\n",
    "        #debug\n",
    "        print (filename, rows, columns)\n",
    "\n",
    "        x_train = np.zeros((rows, columns - 2))\n",
    "        y_train = np.zeros((rows, 1))\n",
    "        qid_train = np.zeros((rows, 1))\n",
    "\n",
    "        for row in range(rows):\n",
    "            for column in range(columns):\n",
    "                if 0 == column:\n",
    "                    y_train[row] = int(data.loc[row, column])\n",
    "                elif 1 == column:\n",
    "                    qid_train[row] = int(data.loc[row, column].split(':')[1])\n",
    "                else:\n",
    "                    x_train[row][column - 2] = float(data.loc[row, column].split(':')[1])\n",
    "            if not row % 10000:\n",
    "                print (\"process: \", str(row))\n",
    "        data_dict[filename].extend([x_train, y_train, qid_train])\n",
    "\n",
    "    np.savez(path_prefix + 'data.npz', X_train=data_dict['train.txt'][0],y_train=data_dict['train.txt'][1],qid_train=data_dict['train.txt'][2],\n",
    "                X_test=data_dict['test.txt'][0], y_test=data_dict['test.txt'][1],qid_test=data_dict['test.txt'][2],\n",
    "                X_vali=data_dict['vali.txt'][0], y_vali=data_dict['vali.txt'][1], qid_vali=data_dict['vali.txt'][2])\n",
    "\n",
    "    print (\"Done\")\n",
    "    \n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load the numpy version data\n",
    "data = np.load(expanduser('~/Desktop/book/Learn2Rank/MSLR-WEB10K/Fold1/data.npz'))\n",
    "X_train, y_train, qid_train = data['X_train'], data['y_train'], data['qid_train']\n",
    "X_vali, y_vali, qid_vali = data['X_vali'], data['y_vali'], data['qid_vali']\n",
    "X_test, y_test, qid_test = data['X_test'], data['y_test'], data['qid_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272.0\n",
      "250000\n",
      "2137\n"
     ]
    }
   ],
   "source": [
    "# Get size in bytes\n",
    "print ((X_train.nbytes + X_vali.nbytes + X_test.nbytes) / 1e6)\n",
    "# Get number of search results\n",
    "print (len(X_train) + len(X_vali) + len(X_test))\n",
    "# Get number of queries\n",
    "print (len(np.unique(qid_train)) + len(np.unique(qid_vali)) + len(np.unique(qid_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the training and validation sets as a big development set.\n",
    "X_dev = np.vstack([X_train, X_vali])\n",
    "y_dev = np.concatenate([y_train, y_vali])\n",
    "qid_dev = np.concatenate([qid_train, qid_vali])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 136)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print (X_dev.shape)\n",
    "print (X_dev.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract a subset of 500 queries to speed up learning\n",
    "def subsample(X, y, qid, size, seed=None):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_qid = np.unique(qid)\n",
    "    qid_mask = rng.permutation(len(unique_qid))[:size]\n",
    "    subset_mask = np.in1d(qid, unique_qid[qid_mask])\n",
    "    return X[subset_mask], y[subset_mask], qid[subset_mask]\n",
    "\n",
    "X_train_small, y_train_small, qid_train_small = subsample(\n",
    "    X_train, y_train, qid_train, 500, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63148, 136)\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "## Double Check data\n",
    "print (X_train_small.shape)\n",
    "print (len(np.unique(qid_train_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63148\n",
      "25606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:18: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 1; dimension is 136 but corresponding boolean dimension is 1\n"
     ]
    }
   ],
   "source": [
    "# adjust training data to be balanced\n",
    "def balance_irrelevant(X, y, qid, seed=None):\n",
    "    \"\"\"Subsample the zero-scored entries\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_qid = np.unique(qid)\n",
    "    final_mask = np.ones(shape=y.shape, dtype=np.bool)\n",
    "    for this_qid in unique_qid:\n",
    "        this_mask = qid == this_qid\n",
    "        this_y = y[this_mask]\n",
    "        relevant = this_y >= 2\n",
    "        ratio = float(np.mean(relevant))\n",
    "        if ratio > 0.5:\n",
    "            # already balanced\n",
    "            continue\n",
    "            \n",
    "        final_mask[this_mask] = np.logical_or(\n",
    "            relevant, np.random.random(len(this_y)) > 0.7) \n",
    "    return X[final_mask], y[final_mask], qid[final_mask]\n",
    "\n",
    "\n",
    "X_train_medium, y_train_medium, qid_train_medium = subsample(\n",
    "    X_train, y_train, qid_train, 1000, seed=0)\n",
    "\n",
    "# Get balanced sample data\n",
    "X_balanced_small, y_balanced_small, qid_balanced_small = balance_irrelevant(\n",
    "    X_train_small, y_train_small, qid_train_small)\n",
    "\n",
    "print(len(y_train_small))\n",
    "print(len(y_balanced_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate ranking with NDCG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dcg(relevances, rank=10):\n",
    "    \"\"\"Discounted cumulative gain at rank (DCG)\"\"\"\n",
    "    relevances = np.asarray(relevances)[:rank]\n",
    "    n_relevances = len(relevances)\n",
    "    if n_relevances == 0:\n",
    "        return 0.\n",
    "\n",
    "    discounts = np.log2(np.arange(n_relevances) + 2)\n",
    "    return np.sum(relevances / discounts)\n",
    " \n",
    " \n",
    "def ndcg(relevances, rank=10):\n",
    "    \"\"\"Normalized discounted cumulative gain (NDGC)\"\"\"\n",
    "    best_dcg = dcg(sorted(relevances, reverse=True), rank)\n",
    "    if best_dcg == 0:\n",
    "        return 0.\n",
    "\n",
    "    return dcg(relevances, rank) / best_dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86253003992915656"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg([2, 4, 0, 1, 1, 0, 0], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13201850690866795"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg([0, 0, 0, 1, 1, 2, 4], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg([0, 0, 0, 1, 1, 2, 4], rank=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg([4, 2, 1, 1, 0, 0, 0], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795191506818377"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_ndcg(y_true, y_pred, query_ids, rank=10):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    query_ids = np.asarray(query_ids)\n",
    "    # assume query_ids are sorted\n",
    "    ndcg_scores = []\n",
    "    previous_qid = query_ids[0]\n",
    "    previous_loc = 0\n",
    "    for loc, qid in enumerate(query_ids):\n",
    "        if previous_qid != qid:\n",
    "            chunk = slice(previous_loc, loc)\n",
    "            ranked_relevances = y_true[chunk][np.argsort(y_pred[chunk])[::-1]]\n",
    "            ndcg_scores.append(ndcg(ranked_relevances, rank=rank))\n",
    "            previous_loc = loc\n",
    "        previous_qid = qid\n",
    "\n",
    "    chunk = slice(previous_loc, loc + 1)\n",
    "    ranked_relevances = y_true[chunk][np.argsort(y_pred[chunk])[::-1]]\n",
    "    ndcg_scores.append(ndcg(ranked_relevances, rank=rank))\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "\n",
    "mean_ndcg([4, 3, 1, 4, 3], [4, 0, 1, 4, 2], [0, 0, 0, 2, 2], rank=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_evaluation(model, X, y, qid):\n",
    "    tic = time()\n",
    "    y_predicted = model.predict(X)\n",
    "    prediction_time = time() - tic\n",
    "    print(\"Prediction time: {:.3f}s\".format(prediction_time))\n",
    "    print(\"NDCG@5 score: {:.3f}\".format(\n",
    "    mean_ndcg(y, y_predicted, qid, rank=5)))\n",
    "    print(\"NDCG@10 score: {:.3f}\".format(\n",
    "    mean_ndcg(y, y_predicted, qid, rank=10)))\n",
    "    print(\"NDCG score: {:.3f}\".format(\n",
    "    mean_ndcg(y, y_predicted, qid, rank=None)))\n",
    "    print(\"R2 score: {:.3f}\".format(r2_score(y, y_predicted)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to adopt different ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 24s, sys: 3.79 s, total: 9min 28s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "etr = ExtraTreesRegressor(n_estimators=200, min_samples_split=5, random_state=1, n_jobs=-1)\n",
    "etr.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 1.363s\n",
      "NDCG@5 score: 0.506\n",
      "NDCG@10 score: 0.521\n",
      "NDCG score: 0.985\n",
      "R2 score: 0.167\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(etr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6364            2.57m\n",
      "         2           0.6252            2.43m\n",
      "         3           0.6159            2.47m\n",
      "         4           0.6074            2.51m\n",
      "         5           0.6009            2.45m\n",
      "         6           0.5949            2.41m\n",
      "         7           0.5896            2.39m\n",
      "         8           0.5851            2.36m\n",
      "         9           0.5811            2.34m\n",
      "        10           0.5776            2.40m\n",
      "        20           0.5557            2.28m\n",
      "        30           0.5433            2.19m\n",
      "        40           0.5362            2.03m\n",
      "        50           0.5303            1.95m\n",
      "        60           0.5262            1.83m\n",
      "        70           0.5228            1.72m\n",
      "        80           0.5196            1.57m\n",
      "        90           0.5165            1.44m\n",
      "       100           0.5139            1.30m\n",
      "       200           0.4925            0.00s\n",
      "CPU times: user 2min 32s, sys: 1.21 s, total: 2min 34s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, random_state=1, verbose=1)\n",
    "gbr.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.421s\n",
      "NDCG@5 score: 0.529\n",
      "NDCG@10 score: 0.546\n",
      "NDCG score: 0.985\n",
      "R2 score: 0.185\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(gbr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6357            9.98m\n",
      "         2           0.6242            9.55m\n",
      "         3           0.6147            9.40m\n",
      "         4           0.6063            9.30m\n",
      "         5           0.5992            9.23m\n",
      "         6           0.5933            9.15m\n",
      "         7           0.5883            9.05m\n",
      "         8           0.5838            9.05m\n",
      "         9           0.5799            9.02m\n",
      "        10           0.5765            8.97m\n",
      "        20           0.5560            8.47m\n",
      "        30           0.5457            7.94m\n",
      "        40           0.5393            7.48m\n",
      "        50           0.5351            6.97m\n",
      "        60           0.5319            6.47m\n",
      "        70           0.5292            5.99m\n",
      "        80           0.5268            5.50m\n",
      "        90           0.5252            5.01m\n",
      "       100           0.5236            4.54m\n",
      "       200           0.5115            0.00s\n",
      "CPU times: user 9min 5s, sys: 2.07 s, total: 9min 7s\n",
      "Wall time: 9min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr2 = GradientBoostingRegressor(n_estimators=200, max_depth=3,\n",
    "                                 learning_rate=0.1, loss='ls',\n",
    "                                 random_state=1, verbose=1)\n",
    "gbr2.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.483s\n",
      "NDCG@5 score: 0.536\n",
      "NDCG@10 score: 0.557\n",
      "NDCG score: 0.985\n",
      "R2 score: 0.198\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(gbr2, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with a baseline linear regression models (with different optimizers and input scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.65 s, sys: 485 ms, total: 3.14 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%time lr = LinearRegression().fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.012s\n",
      "NDCG@5 score: 0.375\n",
      "NDCG@10 score: 0.375\n",
      "NDCG score: 0.375\n",
      "R2 score: 0.147\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(lr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate overfitting by comparing with training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.036s\n",
      "NDCG@5 score: 0.393\n",
      "NDCG@10 score: 0.393\n",
      "NDCG score: 0.393\n",
      "R2 score: 0.141\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(lr, X_dev, y_dev, qid_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interestingly enough, a slight overfitting of the training set from a regression standpoint (higher r2 score) does not seem to cause overfitting from a ranking standpoint. This would have to be checked with cross-validation though.\n",
    "\n",
    "#### Let's evaluate the impact of imput feature normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.63 s, sys: 363 ms, total: 3 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nlr = LinearRegression(normalize=True).fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.010s\n",
      "NDCG@5 score: 0.375\n",
      "NDCG@10 score: 0.375\n",
      "NDCG score: 0.375\n",
      "R2 score: 0.147\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(nlr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 772 ms, sys: 116 ms, total: 888 ms\n",
      "Wall time: 656 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nlr = LinearRegression(normalize=True).fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.010s\n",
      "NDCG@5 score: 0.375\n",
      "NDCG@10 score: 0.375\n",
      "NDCG score: 0.375\n",
      "R2 score: 0.065\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(nlr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_small_scaled = scaler.fit_transform(X_train_small)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Jason/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 s, sys: 22.9 ms, total: 1.73 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sgdlr = SGDRegressor(alpha=1e-7, learning_rate='constant', eta0=1e-5, n_iter=50).fit(X_train_small_scaled, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.012s\n",
      "NDCG@5 score: 0.466\n",
      "NDCG@10 score: 0.496\n",
      "NDCG score: 0.985\n",
      "R2 score: 0.140\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(sgdlr, X_test_scaled, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with a classification to NDCG ranking reduction models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proba_to_relevance(probas):\n",
    "    \"\"\"MCRank-like reduction of classification proba to DCG predictions\"\"\"\n",
    "    rel = np.zeros(probas.shape[0], dtype=np.float32)\n",
    "    for i in range(probas.shape[1]):\n",
    "        rel += i * probas[:, i]\n",
    "    return rel\n",
    "        \n",
    "        \n",
    "class ClassificationRanker(RegressorMixin):\n",
    "    \n",
    "    def __init__(self, base_estimator=None):\n",
    "        self.base_estimator = base_estimator\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.estimator_ = clone(self.base_estimator)\n",
    "        self.scaler_ = StandardScaler()\n",
    "        X = self.scaler_.fit_transform(X)\n",
    "        self.estimator_.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_scaled = self.scaler_.transform(X)\n",
    "        probas = self.estimator_.predict_proba(X_scaled)\n",
    "        return proba_to_relevance(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Jason/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgdlogr = SGDClassifier(loss='modified_huber', alpha=1e-8, n_iter=200, learning_rate='constant', eta0=1e-6, n_jobs=-1)\n",
    "sgdlogrr = ClassificationRanker(sgdlogr)\n",
    "sgdlogrr.fit(X_train_small_scaled, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.128s\n",
      "NDCG@5 score: 0.468\n",
      "NDCG@10 score: 0.500\n",
      "NDCG score: 0.985\n",
      "R2 score: 0.147\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(sgdlogrr, X_test_scaled, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 33s, sys: 1.42 s, total: 3min 34s\n",
      "Wall time: 59.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_features=20, min_samples_split=5,\n",
    "                            random_state=1, n_jobs=-1)\n",
    "rfr = ClassificationRanker(rfc)\n",
    "rfr.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 2.186s\n",
      "NDCG@5 score: 0.506\n",
      "NDCG@10 score: 0.520\n",
      "NDCG score: 0.985\n",
      "R2 score: 0.165\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(rfr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 55s, sys: 2.8 s, total: 5min 58s\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=1)\n",
    "gbr = ClassificationRanker(gbc)\n",
    "gbr.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 1.096s\n",
      "NDCG@5 score: 0.529\n",
      "NDCG@10 score: 0.539\n",
      "NDCG score: 0.985\n",
      "R2 score: 0.174\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(gbr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 2.18 s, total: 1min 15s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ClassificationRanker(ExtraTreesClassifier(n_estimators=200, random_state=1, n_jobs=-1))\n",
    "etc.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 3.186s\n",
      "NDCG@5 score: 0.471\n",
      "NDCG@10 score: 0.490\n",
      "NDCG score: 0.985\n",
      "R2 score: 0.150\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(etc, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
